# MA-BERT

## Instructions

To load MA-BERT and MA-BERT (Shared Softmax):
1. Download the `ma-bert` folder and its pretrained checkpoint
2. Move the folder to the BERT folder in the transformers library: `transformers/models/bert`
3. Execute the code in the `loading_example.ipynb`

To load MA-DistilBERT:
1. Download the `ma-distilbert` folder and its pretrained checkpoint
2. Move the folder to the DistilBERT folder in the transformers library: `transformers/models/distilbert`
3. Execute the code in the `loading_example.ipynb`

## Pretrained Checkpoints
The following contains the links to our pretrained checkpoints: 

| **Model**         |
| :----------: |
| [MA-BERT](https://drive.google.com/uc?id=16jlFRkuuVsB39yP62k7bnitRW9z9Mb1_&export=download) | 
| [MA-BERT (Shared Softmax)](https://drive.google.com/uc?id=1iuONqg13d2Md8mIDwiBaUhycx5cFrRkm&export=download) |
| [MA-DistilBERT](https://drive.google.com/uc?id=1dvnKAJORjcsH85WPp6g5DyTo_ii1attq&export=download) |

## Citations
```
@inproceedings{
anonymous2023mabert,
title={{MA}-{BERT}: Towards Matrix Arithmetic-only {BERT} Inference by Eliminating Complex Non-linear Functions},
author={Anonymous},
booktitle={Submitted to The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=HtAfbHa7LAL},
note={under review}
}
```
